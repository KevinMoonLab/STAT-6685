{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvMlDjs63TBG",
    "outputId": "23308019-5285-4ec1-d418-a90636000535"
   },
   "outputs": [],
   "source": [
    "#### CRITICAL - ENABLE GPU \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from tqdm import tqdm_notebook\n",
    "from uuid import uuid4\n",
    "\n",
    "## Torch Modules\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "## Mount Drive into Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_ppFOaeJxHD",
    "outputId": "046e77f0-81ef-4f6f-ba4b-7cdf60baea3b"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFaPT_uM5YJL"
   },
   "outputs": [],
   "source": [
    "## PyTorch Transformer\n",
    "from pytorch_transformers import RobertaModel, RobertaTokenizer\n",
    "from pytorch_transformers import RobertaForSequenceClassification, RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRzo1v6D4O2t",
    "outputId": "7a4b7dd0-97fd-47b5-8d83-188b7037fb1c"
   },
   "outputs": [],
   "source": [
    "## Check if Cuda is Available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGnE-bXo3-77"
   },
   "outputs": [],
   "source": [
    "## Install PyTorch-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Put6o1wF3-yk"
   },
   "outputs": [],
   "source": [
    "!pip install -U pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkRqK2sM3evs"
   },
   "outputs": [],
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIqwXlCy4g-U",
    "outputId": "19ae84e8-8f1b-4e6c-b606-b1558073d1a0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Important Step - Make sure you upload the data file to the exact location below. If you uploaded correctlt, the following command will run\n",
    "'''\n",
    "\n",
    "!ls drive/'My Drive'/2017-06-custom-intent-engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uudmDs_U39YL"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create the Dataset Path\n",
    "'''\n",
    "\n",
    "\n",
    "dataset_path = \"drive/My Drive/2017-06-custom-intent-engines/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "mJi5RkLC4WsV",
    "outputId": "d9bbc592-bfcc-438c-9bf4-9495781382f6"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "***Explain*** Summarize, in bullet points, what is the code doing?. \n",
    "'''\n",
    "\n",
    "dataset = pd.DataFrame(columns = ['utterance', 'label'])\n",
    "for intent in ['AddToPlaylist', 'BookRestaurant', 'GetWeather', 'PlayMusic', 'RateBook', 'SearchCreativeWork',\n",
    "               'SearchScreeningEvent']:\n",
    "    with open(dataset_path + intent + \"/train_\" + intent + \".json\",\n",
    "              encoding='cp1251') as data_file:\n",
    "        data = json.load(data_file)\n",
    "    print(\"Class: {}, # utterances: {}\".format(intent,len(data[intent])))\n",
    "    texts = []\n",
    "    for i in range(len(data[intent])):\n",
    "        text = ''\n",
    "        for j in range(len(data[intent][i]['data'])):\n",
    "            text += data[intent][i]['data'][j]['text']\n",
    "        dataset = dataset.append({'utterance': text, 'label': intent}, ignore_index=True)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvNXPtT-4Xed",
    "outputId": "3199ab27-bfeb-4bfd-9296-2809e3e8016c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Assigning an Index to each intent. We will use this later\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** Why do we convert labels to indexes?. \n",
    "'''\n",
    "\n",
    "label_to_ix = {}\n",
    "for label in dataset.label:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FtiQj3n5Qqo"
   },
   "outputs": [],
   "source": [
    "## Loading RoBERTa classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ALqUM9f5Qnx",
    "outputId": "07ff5dac-bc51-4085-8171-c29bbaac1069"
   },
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained('roberta-base')\n",
    "config.num_labels = len(list(label_to_ix.values()))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b65wR6MO5Qkm"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading Pretrained tokenizer and instantiating the model from settings in config\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** : a. What is a tokenizer? b. What is special about the following tokenizer?. \n",
    "'''\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "'''\n",
    "***Explain*** :  What is the next line doing?\n",
    "'''\n",
    "\n",
    "model = RobertaForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGKN5aD85Bje"
   },
   "outputs": [],
   "source": [
    "## Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf0ATRkF5LEx"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Some important Feature Engineering\n",
    "'''\n",
    "\n",
    "'''\n",
    "***Explain*** : What are the implications for setting  include_CLS_token = True, include_SEP_token = True ?\n",
    "'''\n",
    "\n",
    "def prepare_features(seq_1, max_seq_length = 300, \n",
    "             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
    "    ## Tokenzine Input\n",
    "    tokens_a = tokenizer.tokenize(seq_1)\n",
    "\n",
    "    ## Truncate\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "    ## Initialize Tokens\n",
    "    tokens = []\n",
    "    if include_CLS_token:\n",
    "        tokens.append(tokenizer.cls_token)\n",
    "    ## Add Tokens and separators\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "\n",
    "    if include_SEP_token:\n",
    "        tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    ## Input Mask \n",
    "    input_mask = [1] * len(input_ids)\n",
    "    ## Zero-pad sequence lenght\n",
    "    if zero_pad:\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "    return torch.tensor(input_ids).unsqueeze(0), input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDx-QxmX5Muc",
    "outputId": "05b15556-4d95-452c-c5e3-fc2f54b3af96"
   },
   "outputs": [],
   "source": [
    "msg = \"My dog is cute!\"\n",
    "prepare_features(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pNqrigh5OIZ"
   },
   "outputs": [],
   "source": [
    "## Dataset Loader Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pexochza5lZq"
   },
   "outputs": [],
   "source": [
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        utterance = self.data.utterance[index]\n",
    "        label = self.data.label[index]\n",
    "        X, _  = prepare_features(utterance)\n",
    "        y = label_to_ix[self.data.label[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCiCHdRL5mH1"
   },
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset=dataset.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
    "test_dataset=dataset.drop(train_dataset.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqOFntri5yW-",
    "outputId": "84da9544-5a8f-4b73-9d7c-456261819062"
   },
   "outputs": [],
   "source": [
    "print(\"FULL Dataset: {}\".format(dataset.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJkGxTWZ5z5d"
   },
   "outputs": [],
   "source": [
    "training_set = Intents(train_dataset)\n",
    "testing_set = Intents(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guYUIlVN51gE",
    "outputId": "5a5e72f5-e069-4804-e13a-ee16931aa0ec"
   },
   "outputs": [],
   "source": [
    "training_set.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuCpzlBq52qV",
    "outputId": "99bceef7-504c-48f1-cfe9-583331a3eb31"
   },
   "outputs": [],
   "source": [
    "model(training_set.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3SH63pK5339"
   },
   "outputs": [],
   "source": [
    "## Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYQq5eSi55mZ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6MIe-fe6PY2"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'drop_last': False,\n",
    "          'num_workers': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egs1bYCe6UOL"
   },
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_set, **params)\n",
    "testing_loader = DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RfrS14A6WGV"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Instantiate the Loss\n",
    "'''\n",
    "'''\n",
    "***Explain*** why cross entropy loss?, also print the model and explain why are not we using softmax at the end?\n",
    "'''\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-05\n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-n3p7ncn6Xst",
    "outputId": "fe5ccff6-39f8-42ad-b1e2-f0dfa27e3e66"
   },
   "outputs": [],
   "source": [
    "## Test Forward Pass\n",
    "inp = training_set.__getitem__(0)[0].cuda()\n",
    "output = model(inp)[0]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AahQQllgKQ4F",
    "outputId": "39e14630-d1a7-467b-9efa-28d89df03770"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cffaf4cc325449c6a7d4670acf3177cf",
      "95675c0005b84a53980b5592204476a3",
      "45ee40a7fb6342309758f174eca9beae",
      "ef195bee3c7648c8ac9aa214cfb214e2",
      "a66c8919baf3401e8b5cf43383de7487",
      "8fe4100312e14bb388c58722e8077176",
      "262a34a2d7d54c05bdece96a627f5239",
      "fc008e0c33104fafbb90e6f335d55357"
     ]
    },
    "id": "xoRJhLY06evJ",
    "outputId": "0de706d6-535d-4fda-ff2f-eb83aaeecb3b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Actually train the model with train data\n",
    "'''\n",
    "'''\n",
    "***Explain*** the Training Code Chunk in detail. Especially what is torch.max() doing here?\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "max_epochs = 3\n",
    "model = model.train()\n",
    "for epoch in tqdm_notebook(range(max_epochs)):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        sent = sent.squeeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "          sent = sent.cuda()\n",
    "          label = label.cuda()\n",
    "        output = model.forward(sent)[0]\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in testing_loader:\n",
    "                sent = sent.squeeze(0)\n",
    "                if torch.cuda.is_available():\n",
    "                  sent = sent.cuda()\n",
    "                  label = label.cuda()\n",
    "                output = model.forward(sent)[0]\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zswPnTBBh9to"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUJIKtiINAHb"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "***Explain*** what is the get_reply function doing?\n",
    "'''\n",
    "def get_reply(msg):\n",
    "  model.eval()\n",
    "  input_msg, _ = prepare_features(msg)\n",
    "  if torch.cuda.is_available():\n",
    "    input_msg = input_msg.cuda()\n",
    "  output = model(input_msg)[0]\n",
    "  _, pred_label = torch.max(output.data, 1)\n",
    "  prediction=list(label_to_ix.keys())[pred_label]\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTMIQUTWNmEp",
    "outputId": "0d885435-d5e3-4abc-c274-2f249401b0b6"
   },
   "outputs": [],
   "source": [
    "label_to_ix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UqEuS5a-NkGo",
    "outputId": "5b166c00-dc56-4b43-a23e-790ebef9e282"
   },
   "outputs": [],
   "source": [
    "'''Different text sentences pass to the model'''\n",
    "\n",
    "get_reply(\"play radiohead song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PoAquwkMO8mB",
    "outputId": "6ba03dcd-f4ae-4fa1-8ba2-c126f1066edf"
   },
   "outputs": [],
   "source": [
    "get_reply(\"it is rainy in Sao Paulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBVApLSXimEa"
   },
   "outputs": [],
   "source": [
    "get_reply(\"sun shinnes all day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu5LiiHOip6l"
   },
   "outputs": [],
   "source": [
    "get_reply(\"low humidity, high altitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZjsxgEIO8g0"
   },
   "outputs": [],
   "source": [
    "get_reply(\"Book tacos for me tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0NOU4AuO8VA"
   },
   "outputs": [],
   "source": [
    "get_reply(\"Book a table for me tonight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLX3-pmy2khU"
   },
   "outputs": [],
   "source": [
    "get_reply(\"I want BBQ tonight\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Classification_RoBERTa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "262a34a2d7d54c05bdece96a627f5239": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45ee40a7fb6342309758f174eca9beae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 67%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fe4100312e14bb388c58722e8077176",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a66c8919baf3401e8b5cf43383de7487",
      "value": 2
     }
    },
    "8fe4100312e14bb388c58722e8077176": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95675c0005b84a53980b5592204476a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66c8919baf3401e8b5cf43383de7487": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cffaf4cc325449c6a7d4670acf3177cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45ee40a7fb6342309758f174eca9beae",
       "IPY_MODEL_ef195bee3c7648c8ac9aa214cfb214e2"
      ],
      "layout": "IPY_MODEL_95675c0005b84a53980b5592204476a3"
     }
    },
    "ef195bee3c7648c8ac9aa214cfb214e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc008e0c33104fafbb90e6f335d55357",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_262a34a2d7d54c05bdece96a627f5239",
      "value": " 2/3 [07:18&lt;03:34, 214.77s/it]"
     }
    },
    "fc008e0c33104fafbb90e6f335d55357": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
